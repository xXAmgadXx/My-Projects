{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "091rKpsIjQrD"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist \n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#*Importing the dataset"
      ],
      "metadata": {
        "id": "epaz0tbbmtyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images , train_labels),(test_images , test_labels) = mnist.load_data()\n",
        "test_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyDUJLsFmj4Z",
        "outputId": "975bea24-0671-4f94-a31b-035ab7657224"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#*subset the data to use only class 0 and class1"
      ],
      "metadata": {
        "id": "b7fy7_ZvnCZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_indexes = (train_labels==0)|(train_labels==1)\n",
        "test_indexes = (test_labels==0)|(test_labels==1)\n",
        "x_train = train_images[train_indexes]\n",
        "y_train = train_labels[train_indexes]\n",
        "\n",
        "x_test = test_images[test_indexes]\n",
        "y_test = test_labels[test_indexes]\n",
        "\n",
        "#reshape training data\n",
        "x_train = x_train.reshape(-1 , 784)\n",
        "y_train = y_train.reshape(-1 , 1)\n",
        "\n",
        "x_test = x_test.reshape(-1 , 784)\n",
        "y_test = y_test.reshape(-1 , 1)"
      ],
      "metadata": {
        "id": "5lZQ2SfXnFwg"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_F39M-vELVhA",
        "outputId": "f3e6eff2-0963-4841-a122-612e1175b1ae"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2115, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#*standardization of the data"
      ],
      "metadata": {
        "id": "LugjColhnw_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_x_train = np.mean(x_train)\n",
        "std_x_train = np.std(x_train)\n",
        "x_train = (x_train - mean_x_train)/std_x_train\n",
        "\n",
        "\n",
        "x_test = (x_test -mean_x_train)/std_x_train"
      ],
      "metadata": {
        "id": "XmiqzhjYnxuA"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aB9oXmyhMz0D",
        "outputId": "3f6c39ac-3411-4d7e-b21d-938f68a0d02b"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2115, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#split the data imto validation data and training data"
      ],
      "metadata": {
        "id": "52jxNUDer8K9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "t2vpcP3yqbIk"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#* implementing Logistic Regression"
      ],
      "metadata": {
        "id": "0Oc1Jh_rokTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)\n",
        "print(x_train.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Udfop7d47W0Y",
        "outputId": "b5792800-2dc8-42cd-8d87-60b8697e52a7"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10132, 784)\n",
            "(10132, 1)\n",
            "(2533, 1)\n",
            "10132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regression_L1(X, y, lr, num_iterations , lambda_param):\n",
        "        \n",
        "        m , n = X.shape     # m is the number of sampes  and n is the number  of features \n",
        "        w = np.zeros((n , 1))\n",
        "        b = 0\n",
        "\n",
        "        for i in range(num_iterations):\n",
        "            z = np.dot(X, w) + b\n",
        "            A = 1 / (1 + np.exp(-z))\n",
        "\n",
        "            # calculate regularized cost function\n",
        "            J = -1/n * np.sum(y*np.log(A) + (1-y)*np.log(1-A)) + lambda_param * np.sum(np.abs(w))\n",
        "\n",
        "\n",
        "             # calculate partial derivatives\n",
        "            dw = 1/m * np.dot(X.T, (A-y)) + lambda_param * np.sign(w)\n",
        "            db = 1/m * np.sum(A-y)\n",
        "\n",
        "            # update weights and bias\n",
        "            w = w - lr * dw\n",
        "            b = b - lr * db\n",
        "\n",
        "            return w , b\n"
      ],
      "metadata": {
        "id": "wCtL9j7Zok_Z"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C45ha6Q1DL4L"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w ,b = logistic_regression_L1(x_train , y_train ,0.01 , 1000 , 0.01)       #L1 when lambda = 0.01\n",
        "\n",
        "z = np.dot(x_test, w) + b\n",
        "A = 1 / (1 + np.exp(-z))\n",
        "y_pred = (A > 0.5).astype(int) \n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: {:.2%}\".format(acc))\n",
        "\n",
        "\n",
        "w ,b = logistic_regression_L1(x_train , y_train ,0.01 , 1000 ,0)         #L1 when lambda = 0.1\n",
        "z = np.dot(x_test, w) + b\n",
        "A = 1 / (1 + np.exp(-z))\n",
        "y_pred2 = (A > 0.5).astype(int)\n",
        "acc = accuracy_score(y_test, y_pred2)\n",
        "print(\"Accuracy2: {:.2%}\".format(acc))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wG8HOIBQA0JS",
        "outputId": "7b5469fa-66f8-423f-e7de-ef4767f09c03"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 99.67%\n",
            "Accuracy2: 99.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression with mini-batch gradient descent"
      ],
      "metadata": {
        "id": "QtXuPxeU43ew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# Define the mini-batch gradient descent function \n",
        "def mini_batch_gradient_descent(x , y , batch_size , ):\n",
        "    num_iterations = 1000\n",
        "    lr = 0.001\n",
        "    w = np.zeros((x.shape[1], 1))\n",
        "    b = 0\n",
        "    N = len(y)\n",
        "    num_batches = int(np.ceil(N / batch_size))\n",
        "    losses = []\n",
        "    for i in range(num_iterations):\n",
        "        for i in range(num_batches):\n",
        "            batch_start = i * batch_size\n",
        "            batch_end = min(batch_start + batch_size, N)\n",
        "            x_batch = x[batch_start:batch_end]\n",
        "            y_batch = y[batch_start:batch_end]\n",
        "            y_hat = np.dot(x_batch, w) + b\n",
        "            dw = (2/batch_size) * np.dot(x_batch.T, (y_hat - y_batch))\n",
        "            db = (2/batch_size) * np.sum(y_hat - y_batch)\n",
        "            w = w - lr * dw\n",
        "            b = b - lr * db\n",
        "            \n",
        "    return w, b\n"
      ],
      "metadata": {
        "id": "Wabsuiks06cP"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_sizes = [128, 256]\n",
        "num_iterations = 1000\n",
        "for batch_size in batch_sizes:\n",
        "    w,b = mini_batch_gradient_descent(x_train, y_train ,batch_size)\n",
        "    mini_batch_acc = np.mean((sigmoid(np.dot(x_test, w)+b) >= 0.5) == y_test)\n",
        "    print(f\"batch_size: {batch_size:.2f},  Accuracy: {mini_batch_acc:.4f}\")"
      ],
      "metadata": {
        "id": "v6y8iQof1QrM",
        "outputId": "9563cf01-766f-4486-b247-a8d36f237ac0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size: 128.00,  Accuracy: 0.7641\n",
            "batch_size: 256.00,  Accuracy: 0.7546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RMS-prop Optimizer"
      ],
      "metadata": {
        "id": "5jFI_qlT7Xof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def Rmsprop_optimizer(x ,y,beta,epsilon,iterations, alpha):\n",
        "        m, n = x.shape\n",
        "        w = np.zeros((n, 1))\n",
        "        b = 0\n",
        "        V_dw = np.zeros((n, 1))\n",
        "        V_db = 0\n",
        "        for i in range(iterations):\n",
        "            z = np.dot(x,w)+b\n",
        "            A = sigmoid(z)\n",
        "            dw = np.mean(np.dot(2 * x.T, (A - y)))\n",
        "            db = np.mean(A - y)\n",
        "            #grad = 1/m * X.T * (h - y)\n",
        "            V_dw = beta * V_dw + (1 - beta) * dw**2 / (1 - math.pow(beta,i+1))\n",
        "            V_db = beta * V_db + (1 - beta) * db**2 / (1 - math.pow(beta,i+1))\n",
        "            w = w - alpha / np.sqrt(V_dw + epsilon) * dw\n",
        "            b = b - alpha / np.sqrt(V_db + epsilon) * db\n",
        "        return w,b"
      ],
      "metadata": {
        "id": "w5ULEby14_B8"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w,b = Rmsprop_optimizer(x_train, y_train.reshape(-1, 1),beta=0.9,epsilon=1e-8,iterations=1000,alpha=0.01)\n",
        "\n",
        "z=np.dot(x_test,w)+b\n",
        "y_pred = (sigmoid(z) >= 0.5)\n",
        "Rmsprop_accuracy = np.mean(y_pred == y_test.reshape(-1, 1))\n",
        "print(\"Accuracy:{:.2%}\".format(Rmsprop_accuracy))"
      ],
      "metadata": {
        "id": "K4aaOwZ-7l5x",
        "outputId": "6a378f4f-ddef-42bf-c466-ab25d8a5f1c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:93.19%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Adam optimizer"
      ],
      "metadata": {
        "id": "8Pu0-GguBGq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Adam_optimizer(x ,y,beta,epsilon, alpha , iterations):\n",
        "        \n",
        "        m, n = x.shape\n",
        "        w = np.zeros((n, 1))\n",
        "        b = 0\n",
        "        V_dw = np.zeros((n, 1))\n",
        "        V_db = 0\n",
        "        momentum_w,momentum_b = 0,0\n",
        "        update_w, update_b = 0,0\n",
        "        beta_1 = 0.9\n",
        "        beta_2 = 0.999\n",
        "        for i in range(iterations):\n",
        "            z = np.dot(x,w)+b\n",
        "            A = sigmoid(z)\n",
        "            dw = np.mean(np.dot(2 * x.T, (A - y)))\n",
        "            db = np.mean(A - y)\n",
        "            \n",
        "            momentum_w = beta_1 * momentum_w + (1 - beta_1) * dw\n",
        "            momentum_b = beta_1 * momentum_b + (1 - beta_1) * db\n",
        "            update_w = beta_2 * update_w + (1 - beta_2) * np.square(dw)\n",
        "            update_b = beta_2 * update_b + (1 - beta_2) * np.square(db)\n",
        "            momentum_w = momentum_w / (1 - beta_1 ** i+1)\n",
        "            momentum_b = momentum_b / (1 - beta_1 ** i+1)\n",
        "            update_w = update_w / (1 - beta_2 ** i+1)\n",
        "            update_b = update_b / (1 - beta_2 ** i+1)\n",
        "\n",
        "            # Update weights and biases\n",
        "            w -= alpha * momentum_w / (np.sqrt(update_w) + epsilon)\n",
        "            b -= alpha * momentum_b / (np.sqrt(update_b) + epsilon)\n",
        "        return w,b"
      ],
      "metadata": {
        "id": "MshjAG4_BF0B"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w,b = Adam_optimizer(x_train, y_train.reshape(-1, 1),beta=0.9,epsilon=1e-8,iterations=1000,alpha=0.01)\n",
        "\n",
        "z = np.dot(x_test , w) + b\n",
        "y_pred = (sigmoid(z) >= 0.5).astype(int)\n",
        " \n",
        "Adam_accuracy = np.mean(y_pred == y_test.reshape(-1, 1))\n",
        "print(\"Accuracy:{:.2%}\".format(Adam_accuracy)"
      ],
      "metadata": {
        "id": "e2TLAP7zByM5",
        "outputId": "2a6714e6-2ba6-4f14-cdcf-616c4dd246e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:93.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# reporting the accuracies\n"
      ],
      "metadata": {
        "id": "F6RpCLDuOY1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "when we implement the L1 regulsrization with lambda= 0.01 we get accuracy = 99.67% (the highest accuracy we get in our case) and lambda =0.1 and get the same accuracy ,L1 gives high accuracy because it helps to prevent the overfitting .\n",
        "*In mini_batch we use batch size 128 we get accuracy = 76.41% \n",
        "and batch size 256 get accuracy = 75.46%  wich might be because the data are relatively small and the two sizes numbers are close .\n",
        "*For RMSprop and Adam optimizers , we obtain accuracy of 93.19% and 93.33%\n",
        "Respectively Both optimizers have shown to be effective in deep learning and are widely used due to their ability to adapt the learning rate according to the gradients ."
      ],
      "metadata": {
        "id": "ggpM9t7GHnOr"
      }
    }
  ]
}